"use strict";(self.webpackChunkluban_docs=self.webpackChunkluban_docs||[]).push([[6794],{2120:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>o,contentTitle:()=>i,default:()=>a,frontMatter:()=>d,metadata:()=>l,toc:()=>c});var s=n(4848),r=n(8453);const d={id:"2kmpka3baqdnhqr",slug:"knowledgebase"},i="Knowledge Base",l={id:"reference/nodes/ai/2kmpka3baqdnhqr",title:"Knowledge Base",description:"Description: Provide knowledge base related features",source:"@site/docs/99-reference/nodes/ai/knowledgebase.mdx",sourceDirName:"99-reference/nodes/ai",slug:"/reference/nodes/ai/knowledgebase",permalink:"/docs/reference/nodes/ai/knowledgebase",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"2kmpka3baqdnhqr",slug:"knowledgebase"},sidebar:"defaultSidebar",previous:{title:"Brain",permalink:"/docs/reference/nodes/ai/brain"},next:{title:"LLM",permalink:"/docs/reference/nodes/ai/llm"}},o={},c=[{value:"Inputs",id:"inputs",level:2},{value:"Outputs",id:"outputs",level:2},{value:"Options",id:"options",level:2}];function h(e){const t={code:"code",h1:"h1",h2:"h2",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.h1,{id:"knowledge-base",children:"Knowledge Base"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Description"}),": Provide knowledge base related features"]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Type"}),": function"]}),"\n",(0,s.jsx)(t.h2,{id:"inputs",children:"Inputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"Conversation Id"})}),(0,s.jsx)(t.td,{children:"text"}),(0,s.jsx)(t.td,{children:"Id of the conversation. If conversation id is empty, it will be treated as a single-turn conversation, and the context functionality will not be provided"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"Question"})}),(0,s.jsx)(t.td,{children:"text"}),(0,s.jsx)(t.td,{children:"User's question"})]})]})]}),"\n",(0,s.jsx)(t.h2,{id:"outputs",children:"Outputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsx)(t.tbody,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"Answer"})}),(0,s.jsx)(t.td,{children:"text"}),(0,s.jsx)(t.td,{children:"Answer provided by LLM, will be empty when outputAsEvent is enabled"})]})})]}),"\n",(0,s.jsx)(t.h2,{id:"options",children:"Options"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"System Context"})}),(0,s.jsx)(t.td,{children:"text"}),(0,s.jsx)(t.td,{children:"The global instructions set for the LLM, that will remain continuously in effect."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"Model"})}),(0,s.jsx)(t.td,{children:"text"}),(0,s.jsx)(t.td,{children:"Model"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"Knowledgebase Context"})}),(0,s.jsx)(t.td,{children:"text"}),(0,s.jsx)(t.td,{children:"Global instructions that guide the LLM on how to handle information retrieved from knowledge base. It is provided to the LLM right after the System Context. The {{knowledge}} tag within it will be replaced with the content retrieved from the knowledge base."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"Knowledge Base"})}),(0,s.jsx)(t.td,{children:"text"}),(0,s.jsx)(t.td,{children:"Knowledge base to query"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"Temperature"})}),(0,s.jsx)(t.td,{children:"number"}),(0,s.jsx)(t.td,{children:"The randomness of the output content"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"Event Output"})}),(0,s.jsx)(t.td,{children:"boolean"}),(0,s.jsx)(t.td,{children:"If enabled, the received content will be organized based on punctuation and added to the event queue, thereby achieving rapid feedback. Otherwise, it will wait for the LLM to complete its output and return it as a single string."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"Event Queue"})}),(0,s.jsx)(t.td,{children:"text"}),(0,s.jsx)(t.td,{children:"```json"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:'"Variable name of the event queue. The LLM event format is: \\n{\\n"name":"llmEvent",\\n"timestamp": number,\\n"parameters"{\\n"text":"Text content of the LLM response",\\n"isEnd": boolean\\n}\\n}.\\nThe timestamp is the time when the request was initiated. Therefore, events generated within a single request will have the same timestamp."'}),(0,s.jsx)(t.td,{}),(0,s.jsx)(t.td,{})]})]})]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-|",children:"| **NodeLogic** | any | Node logic |\n"})})]})}function a(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>l});var s=n(6540);const r={},d=s.createContext(r);function i(e){const t=s.useContext(d);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),s.createElement(d.Provider,{value:t},e.children)}}}]);